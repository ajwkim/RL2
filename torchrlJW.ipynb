{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tensordict import TensorDict\n",
    "T, F = True, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorDict\n",
    "- source = 딕트\n",
    "- batch_size = [배치사이즈]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        key1: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        key2: Tensor(shape=torch.Size([5, 5, 6]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsize = 5\n",
    "x = TensorDict({'key1': torch.zeros(bsize, 3),\n",
    "                'key2': torch.zeros(bsize, 5, 6, dtype=torch.bool)},\n",
    "                [bsize])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.batch_size                    # .batch_size 속성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert x['key1'] is x.get('key1')\n",
    "\n",
    "x['key1']                         # [키] -> 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### operations along batch dim\n",
    "- x[인덱싱] / x.gather\n",
    "- reshape/view\n",
    "- permute\n",
    "- (un)squeeze/expand\n",
    "- unbind/split\n",
    "- torch.stack/cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        key1: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        key2: Tensor(shape=torch.Size([5, 6]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2]                            # 인덱싱 -> new 텐서딕트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5]) torch.Size([2, 5, 1]) tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]])\n"
     ]
    }
   ],
   "source": [
    "x1 = TensorDict(dict(key1=torch.zeros(bsize, 1),\n",
    "                     key2=torch.zeros(bsize, 5, 6, dtype=torch.bool)),\n",
    "                [bsize])\n",
    "x2 = TensorDict(dict(key1=torch.ones(bsize, 1),\n",
    "                     key2=torch.ones(bsize, 5, 6, dtype=torch.bool)),\n",
    "                [bsize])\n",
    "x = torch.stack((x1, x2))\n",
    "\n",
    "print(x.batch_size, x['key1'].size(), x['key1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10]), torch.Size([10, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1).batch_size, x.view(-1).get('key1').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2]), torch.Size([5, 2, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.permute(1, 0).batch_size, x.permute(1, 0).get('key1').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2, 5]), torch.Size([3, 2, 5, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.expand(3, *x.batch_size).batch_size, x.expand(3, *x.batch_size).get('key1').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        key1: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        key2: TensorDict(\n",
       "            fields={\n",
       "                subkey1: Tensor(shape=torch.Size([5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([5, 2]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nested TensorDict\n",
    "\n",
    "x = TensorDict({'key1': torch.zeros(bsize, 3),\n",
    "                'key2': TensorDict({'subkey1': torch.zeros(bsize, 2, 1)}, [bsize, 2]) },\n",
    "                [bsize])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <AD0702F8-F0F4-3872-8C19-A834018634B4> /opt/homebrew/Caskroom/miniconda/base/envs/py311/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "from torchrl.data import ReplayBuffer\n",
    "\n",
    "buffer = ReplayBuffer()         # default size 1000, ListStorage\n",
    "\n",
    "print(len(buffer))\n",
    "\n",
    "buffer.extend(range(2000))      # extend / add\n",
    "print(len(buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'a', 'a']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchrl.data import LazyMemmapStorage, LazyTensorStorage, ListStorage\n",
    "\n",
    "size = 100\n",
    "\n",
    "buffer_list = ReplayBuffer(storage=ListStorage(size),       \n",
    "                           collate_fn=lambda x: x)          # numerical data 아니면\n",
    "\n",
    "buffer_list.extend(['a', 0, 'b'])\n",
    "\n",
    "buffer_list.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensordict import TensorDict\n",
    "\n",
    "buffer_lazytensor = ReplayBuffer(storage=LazyTensorStorage(size))\n",
    "\n",
    "data = TensorDict({'a': torch.arange(12).view(3, 4),\n",
    "                   ('b', 'c'): torch.arange(15).view(3, 5)},\n",
    "                   batch_size=[3])\n",
    "buffer_lazytensor.extend(data)\n",
    "len(buffer_lazytensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        a: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        b: TensorDict(\n",
       "            fields={\n",
       "                c: Tensor(shape=torch.Size([5, 5]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
       "            batch_size=torch.Size([5]),\n",
       "            device=cpu,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = buffer_lazytensor.sample(5)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  5,  6,  7],\n",
       "        [ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [ 0,  1,  2,  3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6,  7,  8,  9],\n",
       "        [ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [ 0,  1,  2,  3,  4]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['b', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "TensorDict(\n",
      "    fields={\n",
      "        a: Tensor(shape=torch.Size([12, 4]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        b: TensorDict(\n",
      "            fields={\n",
      "                c: Tensor(shape=torch.Size([12, 5]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([12]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        index: Tensor(shape=torch.Size([12]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "    batch_size=torch.Size([12]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 2, 2, 1, 0, 2, 2, 2, 0, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchrl.data import TensorDictReplayBuffer\n",
    "\n",
    "buffer = TensorDictReplayBuffer(storage=LazyTensorStorage(size), batch_size=12)\n",
    "\n",
    "buffer.extend(data)\n",
    "print(len(buffer))\n",
    "\n",
    "sample = buffer.sample()\n",
    "print(sample)\n",
    "sample['index']                 # 'index' key of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
